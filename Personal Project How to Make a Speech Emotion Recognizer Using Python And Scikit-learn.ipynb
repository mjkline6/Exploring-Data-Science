{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center; color:green\";> Applied Data Science </h1>\n",
    "<center>\n",
    "\n",
    "\n",
    "<h2 style=\"text-align:center; color:blue\";> Personal Project: Outligning and Creating A Speech Emotion Recognizer Using Python And Scikit-learn </h2>\n",
    "\n",
    "<h2 style=\"text-align:center; color:Black\";> Matthew Kline </h2>\n",
    "<h3 style=\"text-align:center; color:Black\";> 8/1/2021 </h3>\n",
    "\n",
    "<h4 style=\"text-align:left; color:orange\";> Building a Speech Emotion Recognition system that detects emotion from human speech tone using the Scikit-Learn library,Python and Librosa </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is Speech Emotion Recognition?**\n",
    "\n",
    "Speech Emotion Recognition, abbreviated as SER, is the act of attempting to recognize human emotion and affective states from speech.This is capitalizing on the fact that voice often reflects underlying emotion through tone and pitch. This is also the phenomenon thatanimals like dogs and horses employ to be able to understand human emotion.\n",
    "\n",
    "SER is tough because emotions are subjective and annotating audio is challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is librosa?**\n",
    "\n",
    "librosa is a Python library for analyzing audio and music. It has a flatter package layout, standardizes interfaces and names, backwards compatibility, modular functions, and readable code. Further, in this Python mini-project, we demonstrate how to install it (and a few otherpackages) with pip.\n",
    "\n",
    "**What is JupyterLab?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JupyterLab which is an open-source, web-based UI for Project Jupyter and it has all basic functionalities of theJupyter Notebook, like notebooks, terminals, text editors, file browsers, rich outputs, and more. However, it also provides improvedsupport for third party extensions. It comes bubdled with the Anaconda Data Science Framework if you want to try it out, BUT you canjust keep using your Jupyter Notebook and all wii be fine.\n",
    "\n",
    "**Speech Emotion Recognition – Objective**\n",
    "\n",
    "To build a model to recognize emotion from speech using the librosa and sklearn libraries and the RAVDESS dataset.\n",
    "\n",
    "**Speech Emotion Recognition – About the Python Mini Project**\n",
    "\n",
    "In this Python mini project, we will use the libraries librosa, soundfile, and sklearn (among others) to build a model using anMLPClassifier. This will be able to recognize emotion from sound files. We will load the data, extract features from it, then split the datasetinto training and testing sets. Then, we’ll initialize an MLPClassifier and train the model. Finally, we’ll calculate the accuracy of our model.\n",
    "\n",
    "**The Dataset**\n",
    "\n",
    "For this Python mini project, I used the RAVDESS dataset; this is the Ryerson Audio-Visual Database of Emotional Speech and Song dataset, and is free to download. This dataset has 7356 files rated by 247 individuals 10 times on emotional validity, intensity, andgenuineness. The entire dataset is 24.8GB from 24 actors, but I have lowered the sample rate on all the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File Summary**\n",
    "\n",
    "In total, the RAVDESS collection includes 7356 files (2880+2024+1440+1012 files).\n",
    "\n",
    "**File naming convention**\n",
    "\n",
    "Each of the 7356 RAVDESS files has a unique filename. The filename consists of a 7-part numerical identifier (e.g., 02-01-06-01-02-01-12.mp4). These identifiers define the stimulus characteristics:\n",
    "\n",
    "**Filename identifiers**\n",
    "\n",
    "-  Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "-  Vocal channel (01 = speech, 02 = song).\n",
    "-  Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "-  Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "-  Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "-  Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "-  Actor (01 to 24. Odd numbered actors are male, even numbered actors are female)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Video-only (02)\n",
    "- Speech (01)\n",
    "- Fearful (06)\n",
    "- Normal intensity (01)\n",
    "- Statement \"dogs\" (02)\n",
    "- 1st Repetition (01)\n",
    "- 12th Actor (12)\n",
    "- Female, as the actor ID number is even."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prerequisites</h3>\n",
    "\n",
    "\n",
    "\n",
    "**pip installl** ibrosa soundfile numpy **sklearn** pyaudiousing_anaconda_terminal.png\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole pipeline is as follows (same as any machine learning pipeline):\n",
    "\n",
    "- Preparing the Dataset: Here, I downloaded and converted the dataset to be suited for extraction.\n",
    "- Loading the Dataset: This process is about loading the dataset in Python which involves extracting audio features, such as obtaining different features such as power, pitch and vocal tract configuration from the speech signal, I used librosa library to do that.\n",
    "- Training the Model: After I prepare and load the dataset, I simply train it on a suited sklearn model.\n",
    "- Testing the Model: Measuring how good my model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile # to read audio file\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa# to extract speech features\n",
    "import glob\n",
    "import os \n",
    "import pickle# to save model after training\n",
    "from sklearn.model_selection import train_test_split# for splitting training and testing\n",
    "from sklearn.neural_network import MLPClassifier# multi-layer perceptron model\n",
    "from sklearn.metrics import accuracy_score# to measure how good we are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define a function extract_feature to extract the mfcc, chroma, and mel features from a sound file. This function takes 4 parameters-the file name and three Boolean parameters for the three features:\n",
    "2. mfcc: Mel Frequency Cepstral Coefficient, represents the short-term power spectrum of a sound\n",
    "3. chroma: Pertains to the 12 different pitch classes45. mel: Mel Spectrogram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "            result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now, I define a dictionary to hold numbers and the emotions available in the RAVDESS dataset, and a list to hold those we wantcalm, happy, fearful, disgust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    " '01':'neutral',\n",
    " '02':'calm',\n",
    " '03':'happy',\n",
    " '04':'sad',\n",
    " '05':'angry',\n",
    " '06':'fearful',\n",
    " '07':'disgust',\n",
    " '08':'surprised'\n",
    "}\n",
    "# Emotions to observe\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now, I load the data with a function load_data() – this takes in the relative size of the test set as parameter. x and y are empty\n",
    "lists; I use the glob() function from the glob module to get all the pathnames for the sound files in our dataset. The pattern we use\n",
    "for this is: **“ravdess-data\\Actor_\\.wav”**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, for each such path, get the basename of the file, the emotion by splitting the name around ‘-’ and extracting the third\n",
    "value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"ravdess-data\\\\Actor_*\\\\*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Using the emotions dictionary, this number is turned into an emotion, and my function checks whether this emotion is in the\n",
    "list of observed_emotions; if not, it continues to the next file. It makes a call to extract_feature and stores what is returned in\n",
    "‘feature’. Then, it appends the feature to x and the emotion to y. So, the list x holds the features and y holds the\n",
    "emotions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I call the function train_test_split with these, the test size, and a random state value, and return that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Time to split the dataset into training and testing sets! Let’s keep the test set 25% of everything and use the load_data function for\n",
    "this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "x_train,x_test,y_train,y_test=load_data(test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Observe the shape of the training and testing datasets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 192)\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the training and testing datasets\n",
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. And get the number of features extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "# Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Now, I initialize an MLPClassifier. This is a Multi-layer Perceptron Classifier; it optimizes the log-loss function using different\n",
    "optimizers (lbfgs, adam or stochastic gradient descent). Recall that the MLPClassifier has an internal neural network for the purpose\n",
    "of classification, and is a feed-forward CNN model.\n",
    "\n",
    "I pretty much played around with the parmaeters of the MLPClassifier to get the best possible hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Multi Layer Perceptron Classifier\n",
    "model=MLPClassifier(solver='adam', alpha=0.005, batch_size=200, epsilon=1e-08, hidden_layer_sizes=(400,),\n",
    "    learning_rate='adaptive', max_iter=700)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.005, batch_size=200, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(400,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_iter=700, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Plot the loss during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A loss function, also known as a cost function, takes into account the probabilities or uncertainty of a prediction based on how much the prediction varies from the true value. This gives us a more nuanced view into how well the model is performing\n",
    "\n",
    "Unlike accuracy, loss is not a percentage — it is a summation of the errors made for each sample in training or validation sets. Loss is\n",
    "often used in the training process to find the \"best\" parameter values for the model (e.g. weights in neural network). During the training\n",
    "process the goal is to minimize this value.\n",
    "|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = model.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6, 4))\n",
    "plt.plot(loss_values, color=\"red\", label = 'training loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss');\n",
    "#legend\n",
    "plt.legend(loc='upper right')\n",
    "#title\n",
    "plt.title('Training Loss Per Epoch: Speech Emotion Recognition')\n",
    "#show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. **Model Predictions**\n",
    "Let’s predict the values for the test set. This gives us y_pred (the predicted emotions for the features in the test set).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for the test set\n",
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. **Model Performance**\n",
    "To calculate the accuracy of our model, we’ll call up the accuracy_score() function we imported from sklearn. Finally, we’ll round the\n",
    "accuracy to 2 decimal places and print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.52%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of my model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accurracy: 75.52 %\n"
     ]
    }
   ],
   "source": [
    "print('test set accurracy: {0:.2f} %'.format(100*model.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance on a single waveform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictied emotion from the speech is: disgust\n"
     ]
    }
   ],
   "source": [
    "print('The predictied emotion from the speech is: {}'\n",
    " .format(model.predict([x_test[22]])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true emotion is: disgust\n"
     ]
    }
   ],
   "source": [
    "print('The true emotion is: {}'.format(y_test[22]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pickle (serialize) and save the trained classifier to a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialization with Python's Pickle\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "dest = os.path.join('classifiers', 'pkl_objects')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "\n",
    "pickle.dump(model, open(os.path.join(dest, 'ser_classifier.pkl'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the saved classifier into memory**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved the trained classifier into memory\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "os.chdir('classifiers')\n",
    "ser_model = pickle.load(open(os.path.join('pkl_objects', 'ser_classifier.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the re-loaded model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reloaded model predicts the emotion from the speech is:calm\n"
     ]
    }
   ],
   "source": [
    "print('The reloaded model predicts the emotion from the speech is:{}'\n",
    " .format(ser_model.predict([x_test[33]])[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true emotion is: fearful\n"
     ]
    }
   ],
   "source": [
    "print('The true emotion is: {}'.format(y_test[33]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Summary</h3>\n",
    "\n",
    "In this Python, Machine Learning, Mini-Project, I learned to recognize emotions from speech. We used an MLPClassifier for the neural\n",
    "network and and made use of the soundfile library to read the sound file, and the librosa library to extract features from it.We also\n",
    "serialized the model and tested the reloaded model on unseen data and saw that it performed well. So, as you've seen, the model\n",
    "delivered an accuracy of 70-80%, which is not bad for our first attempt at building a speech emotion recognizer"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Classification of MNIST with Scikit Learn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
