{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style='color:blue'>Matthew Kline</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "I am using this project to demonstrate an end to end understanding of data science while exploring machine learning methodologies.  The processes I will explore are as follows:\n",
    "\n",
    "- Frame the problem and look at the big picture.\n",
    "- Get the data\n",
    "- Explore the data to gain insights. \n",
    "- Prepare the data to expose the underlying data patterns to Machine Learning algorithms. \n",
    "- Explore many different models and short-list the best ones. \n",
    "- Fine-tune my models and combine them into a great solution. \n",
    "- Cross analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:purple'> Frame the Problem</h2>\n",
    "\n",
    "### Sensor Data\n",
    "The data source as well as the exact nature of the data is confidential. Each data instance contains 12 real-valued input attributes. Each input attribute represents a sensor designed to detect the presence of one or two groups of substances. As an alternative, the sensor readings may represent a 'false alrarm'. \n",
    "\n",
    "- Substance 1 is represented by the value 'one' in the class attribute column. \n",
    "- Substance 2 is represented by the value 'two' in the class attribute column. \n",
    "- A false alarm is represented by the value 'three' in the class attribute column. \n",
    "\n",
    "The problem in framed as a **supervised learning** problem: Predict the class of a substance from sensor data using the given measurements in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:green'>Exploratory Data Analysis</h2>\n",
    "<h3>Using Pandas to load my data into a dataframe</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.406</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>5.691</td>\n",
       "      <td>5.906</td>\n",
       "      <td>1.763</td>\n",
       "      <td>2.726</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>1.859</td>\n",
       "      <td>5.083</td>\n",
       "      <td>5.503</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.680</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>5.461</td>\n",
       "      <td>5.923</td>\n",
       "      <td>1.589</td>\n",
       "      <td>2.799</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.821</td>\n",
       "      <td>5.099</td>\n",
       "      <td>5.601</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.738</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>5.680</td>\n",
       "      <td>5.916</td>\n",
       "      <td>1.844</td>\n",
       "      <td>2.798</td>\n",
       "      <td>1.0280</td>\n",
       "      <td>0.6238</td>\n",
       "      <td>1.759</td>\n",
       "      <td>5.127</td>\n",
       "      <td>5.535</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.503</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>5.703</td>\n",
       "      <td>-9999.000</td>\n",
       "      <td>1.711</td>\n",
       "      <td>2.856</td>\n",
       "      <td>1.1500</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>1.736</td>\n",
       "      <td>5.094</td>\n",
       "      <td>5.452</td>\n",
       "      <td>0.7690</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.744</td>\n",
       "      <td>0.5884</td>\n",
       "      <td>5.532</td>\n",
       "      <td>5.911</td>\n",
       "      <td>1.792</td>\n",
       "      <td>2.886</td>\n",
       "      <td>1.0310</td>\n",
       "      <td>0.5627</td>\n",
       "      <td>1.868</td>\n",
       "      <td>4.989</td>\n",
       "      <td>5.382</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.524</td>\n",
       "      <td>0.6311</td>\n",
       "      <td>5.773</td>\n",
       "      <td>5.822</td>\n",
       "      <td>1.803</td>\n",
       "      <td>2.800</td>\n",
       "      <td>1.0490</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>1.885</td>\n",
       "      <td>5.100</td>\n",
       "      <td>5.479</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.570</td>\n",
       "      <td>0.4834</td>\n",
       "      <td>5.804</td>\n",
       "      <td>5.887</td>\n",
       "      <td>1.708</td>\n",
       "      <td>2.894</td>\n",
       "      <td>1.0830</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>1.807</td>\n",
       "      <td>5.062</td>\n",
       "      <td>5.336</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.489</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>5.790</td>\n",
       "      <td>5.900</td>\n",
       "      <td>1.849</td>\n",
       "      <td>2.919</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>1.809</td>\n",
       "      <td>5.216</td>\n",
       "      <td>5.555</td>\n",
       "      <td>0.6897</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.503</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>5.686</td>\n",
       "      <td>5.892</td>\n",
       "      <td>1.714</td>\n",
       "      <td>2.822</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>0.6079</td>\n",
       "      <td>1.840</td>\n",
       "      <td>5.001</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.425</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>5.732</td>\n",
       "      <td>5.912</td>\n",
       "      <td>1.793</td>\n",
       "      <td>2.726</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.6104</td>\n",
       "      <td>1.749</td>\n",
       "      <td>5.020</td>\n",
       "      <td>5.514</td>\n",
       "      <td>0.8081</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input 1  Input 2  Input 3   Input 4  Input 5  Input 6  Input 7  Input 8  \\\n",
       "0    4.406   0.6116    5.691     5.906    1.763    2.726   0.9607   0.6055   \n",
       "1    4.680   0.5322    5.461     5.923    1.589    2.799   0.9937   0.6250   \n",
       "2    4.738   0.5298    5.680     5.916    1.844    2.798   1.0280   0.6238   \n",
       "3    4.503   0.5273    5.703 -9999.000    1.711    2.856   1.1500   0.6201   \n",
       "4    4.744   0.5884    5.532     5.911    1.792    2.886   1.0310   0.5627   \n",
       "5    4.524   0.6311    5.773     5.822    1.803    2.800   1.0490   0.6836   \n",
       "6    4.570   0.4834    5.804     5.887    1.708    2.894   1.0830   0.4919   \n",
       "7    4.489   0.5054    5.790     5.900    1.849    2.919   0.9082   0.6055   \n",
       "8    4.503   0.6091    5.686     5.892    1.714    2.822   1.0300   0.6079   \n",
       "9    4.425   0.6091    5.732     5.912    1.793    2.726   1.0950   0.6104   \n",
       "\n",
       "   Input 9  Input 10   Input 11   Input 12 class  \n",
       "0    1.859      5.083      5.503    0.7544   one  \n",
       "1    1.821      5.099      5.601    0.9546   one  \n",
       "2    1.759      5.127      5.535    0.7275   one  \n",
       "3    1.736      5.094      5.452    0.7690   one  \n",
       "4    1.868      4.989      5.382    0.6665   one  \n",
       "5    1.885      5.100      5.479    0.6958   one  \n",
       "6    1.807      5.062      5.336    0.8447   one  \n",
       "7    1.809      5.216      5.555    0.6897   one  \n",
       "8    1.840      5.001      5.360    0.9521   one  \n",
       "9    1.749      5.020      5.514    0.8081   one  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Sensor_Data.csv')\n",
    "\n",
    "df.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Summary statistics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "      <td>1666.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-134.420804</td>\n",
       "      <td>-118.114677</td>\n",
       "      <td>-109.102194</td>\n",
       "      <td>-91.399119</td>\n",
       "      <td>-125.040359</td>\n",
       "      <td>-130.537302</td>\n",
       "      <td>-77.319851</td>\n",
       "      <td>-125.663162</td>\n",
       "      <td>-95.131987</td>\n",
       "      <td>-75.160382</td>\n",
       "      <td>-88.122777</td>\n",
       "      <td>-63.045762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1167.492978</td>\n",
       "      <td>1089.498394</td>\n",
       "      <td>1062.557232</td>\n",
       "      <td>975.926752</td>\n",
       "      <td>1115.959694</td>\n",
       "      <td>1141.932576</td>\n",
       "      <td>880.138338</td>\n",
       "      <td>1115.889116</td>\n",
       "      <td>975.558523</td>\n",
       "      <td>880.331222</td>\n",
       "      <td>944.963450</td>\n",
       "      <td>810.287385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.018500</td>\n",
       "      <td>0.820300</td>\n",
       "      <td>4.783250</td>\n",
       "      <td>3.479500</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.600275</td>\n",
       "      <td>0.278300</td>\n",
       "      <td>0.181900</td>\n",
       "      <td>0.394000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>0.764200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.073000</td>\n",
       "      <td>1.522500</td>\n",
       "      <td>5.340500</td>\n",
       "      <td>5.094500</td>\n",
       "      <td>0.795300</td>\n",
       "      <td>1.578000</td>\n",
       "      <td>0.523100</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>0.728750</td>\n",
       "      <td>2.192000</td>\n",
       "      <td>1.345000</td>\n",
       "      <td>1.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.508000</td>\n",
       "      <td>3.122250</td>\n",
       "      <td>5.599000</td>\n",
       "      <td>5.649000</td>\n",
       "      <td>1.461250</td>\n",
       "      <td>2.177750</td>\n",
       "      <td>0.965600</td>\n",
       "      <td>0.504475</td>\n",
       "      <td>1.233000</td>\n",
       "      <td>4.968000</td>\n",
       "      <td>1.907500</td>\n",
       "      <td>5.337750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5.105000</td>\n",
       "      <td>4.675000</td>\n",
       "      <td>5.944000</td>\n",
       "      <td>6.011000</td>\n",
       "      <td>2.571000</td>\n",
       "      <td>3.638000</td>\n",
       "      <td>2.446000</td>\n",
       "      <td>1.199000</td>\n",
       "      <td>2.278000</td>\n",
       "      <td>5.312000</td>\n",
       "      <td>5.640000</td>\n",
       "      <td>5.825000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Input 1      Input 2      Input 3      Input 4      Input 5  \\\n",
       "count  1666.000000  1666.000000  1666.000000  1666.000000  1666.000000   \n",
       "mean   -134.420804  -118.114677  -109.102194   -91.399119  -125.040359   \n",
       "std    1167.492978  1089.498394  1062.557232   975.926752  1115.959694   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%       3.018500     0.820300     4.783250     3.479500     0.408900   \n",
       "50%       4.073000     1.522500     5.340500     5.094500     0.795300   \n",
       "75%       4.508000     3.122250     5.599000     5.649000     1.461250   \n",
       "max       5.105000     4.675000     5.944000     6.011000     2.571000   \n",
       "\n",
       "           Input 6      Input 7      Input 8      Input 9    Input 10   \\\n",
       "count  1666.000000  1666.000000  1666.000000  1666.000000  1666.000000   \n",
       "mean   -130.537302   -77.319851  -125.663162   -95.131987   -75.160382   \n",
       "std    1141.932576   880.138338  1115.889116   975.558523   880.331222   \n",
       "min   -9999.000000 -9999.000000 -9999.000000 -9999.000000 -9999.000000   \n",
       "25%       0.600275     0.278300     0.181900     0.394000     1.420000   \n",
       "50%       1.578000     0.523100     0.300300     0.728750     2.192000   \n",
       "75%       2.177750     0.965600     0.504475     1.233000     4.968000   \n",
       "max       3.638000     2.446000     1.199000     2.278000     5.312000   \n",
       "\n",
       "         Input 11      Input 12  \n",
       "count  1666.000000  1666.000000  \n",
       "mean    -88.122777   -63.045762  \n",
       "std     944.963450   810.287385  \n",
       "min   -9999.000000 -9999.000000  \n",
       "25%       1.130000     0.764200  \n",
       "50%       1.345000     1.029000  \n",
       "75%       1.907500     5.337750  \n",
       "max       5.640000     5.825000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1666, 13)\n"
     ]
    }
   ],
   "source": [
    "#Display the shape\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using Pandas dataframe to find bad or missing data</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.406</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>5.691</td>\n",
       "      <td>5.906</td>\n",
       "      <td>1.763</td>\n",
       "      <td>2.726</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>1.859</td>\n",
       "      <td>5.083</td>\n",
       "      <td>5.503</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.680</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>5.461</td>\n",
       "      <td>5.923</td>\n",
       "      <td>1.589</td>\n",
       "      <td>2.799</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.821</td>\n",
       "      <td>5.099</td>\n",
       "      <td>5.601</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.738</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>5.680</td>\n",
       "      <td>5.916</td>\n",
       "      <td>1.844</td>\n",
       "      <td>2.798</td>\n",
       "      <td>1.0280</td>\n",
       "      <td>0.6238</td>\n",
       "      <td>1.759</td>\n",
       "      <td>5.127</td>\n",
       "      <td>5.535</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.744</td>\n",
       "      <td>0.5884</td>\n",
       "      <td>5.532</td>\n",
       "      <td>5.911</td>\n",
       "      <td>1.792</td>\n",
       "      <td>2.886</td>\n",
       "      <td>1.0310</td>\n",
       "      <td>0.5627</td>\n",
       "      <td>1.868</td>\n",
       "      <td>4.989</td>\n",
       "      <td>5.382</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.524</td>\n",
       "      <td>0.6311</td>\n",
       "      <td>5.773</td>\n",
       "      <td>5.822</td>\n",
       "      <td>1.803</td>\n",
       "      <td>2.800</td>\n",
       "      <td>1.0490</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>1.885</td>\n",
       "      <td>5.100</td>\n",
       "      <td>5.479</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.570</td>\n",
       "      <td>0.4834</td>\n",
       "      <td>5.804</td>\n",
       "      <td>5.887</td>\n",
       "      <td>1.708</td>\n",
       "      <td>2.894</td>\n",
       "      <td>1.0830</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>1.807</td>\n",
       "      <td>5.062</td>\n",
       "      <td>5.336</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.489</td>\n",
       "      <td>0.5054</td>\n",
       "      <td>5.790</td>\n",
       "      <td>5.900</td>\n",
       "      <td>1.849</td>\n",
       "      <td>2.919</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>1.809</td>\n",
       "      <td>5.216</td>\n",
       "      <td>5.555</td>\n",
       "      <td>0.6897</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.503</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>5.686</td>\n",
       "      <td>5.892</td>\n",
       "      <td>1.714</td>\n",
       "      <td>2.822</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>0.6079</td>\n",
       "      <td>1.840</td>\n",
       "      <td>5.001</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.425</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>5.732</td>\n",
       "      <td>5.912</td>\n",
       "      <td>1.793</td>\n",
       "      <td>2.726</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.6104</td>\n",
       "      <td>1.749</td>\n",
       "      <td>5.020</td>\n",
       "      <td>5.514</td>\n",
       "      <td>0.8081</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.534</td>\n",
       "      <td>0.6287</td>\n",
       "      <td>5.411</td>\n",
       "      <td>5.896</td>\n",
       "      <td>1.760</td>\n",
       "      <td>3.008</td>\n",
       "      <td>1.1160</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>1.854</td>\n",
       "      <td>4.971</td>\n",
       "      <td>5.503</td>\n",
       "      <td>0.7507</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Input 1  Input 2  Input 3  Input 4  Input 5  Input 6  Input 7  Input 8  \\\n",
       "0     4.406   0.6116    5.691    5.906    1.763    2.726   0.9607   0.6055   \n",
       "1     4.680   0.5322    5.461    5.923    1.589    2.799   0.9937   0.6250   \n",
       "2     4.738   0.5298    5.680    5.916    1.844    2.798   1.0280   0.6238   \n",
       "4     4.744   0.5884    5.532    5.911    1.792    2.886   1.0310   0.5627   \n",
       "5     4.524   0.6311    5.773    5.822    1.803    2.800   1.0490   0.6836   \n",
       "6     4.570   0.4834    5.804    5.887    1.708    2.894   1.0830   0.4919   \n",
       "7     4.489   0.5054    5.790    5.900    1.849    2.919   0.9082   0.6055   \n",
       "8     4.503   0.6091    5.686    5.892    1.714    2.822   1.0300   0.6079   \n",
       "9     4.425   0.6091    5.732    5.912    1.793    2.726   1.0950   0.6104   \n",
       "10    4.534   0.6287    5.411    5.896    1.760    3.008   1.1160   0.6116   \n",
       "\n",
       "    Input 9  Input 10   Input 11   Input 12 class  \n",
       "0     1.859      5.083      5.503    0.7544   one  \n",
       "1     1.821      5.099      5.601    0.9546   one  \n",
       "2     1.759      5.127      5.535    0.7275   one  \n",
       "4     1.868      4.989      5.382    0.6665   one  \n",
       "5     1.885      5.100      5.479    0.6958   one  \n",
       "6     1.807      5.062      5.336    0.8447   one  \n",
       "7     1.809      5.216      5.555    0.6897   one  \n",
       "8     1.840      5.001      5.360    0.9521   one  \n",
       "9     1.749      5.020      5.514    0.8081   one  \n",
       "10    1.854      4.971      5.503    0.7507   one  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace([-9999.000], np.nan)\n",
    "df = df.dropna()\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1463, 13)\n"
     ]
    }
   ],
   "source": [
    "# shape of data in dataframe after cleansing \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input 1</th>\n",
       "      <th>Input 2</th>\n",
       "      <th>Input 3</th>\n",
       "      <th>Input 4</th>\n",
       "      <th>Input 5</th>\n",
       "      <th>Input 6</th>\n",
       "      <th>Input 7</th>\n",
       "      <th>Input 8</th>\n",
       "      <th>Input 9</th>\n",
       "      <th>Input 10</th>\n",
       "      <th>Input 11</th>\n",
       "      <th>Input 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Input 1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.572129</td>\n",
       "      <td>0.939954</td>\n",
       "      <td>0.950208</td>\n",
       "      <td>0.775150</td>\n",
       "      <td>0.894622</td>\n",
       "      <td>0.700969</td>\n",
       "      <td>0.687356</td>\n",
       "      <td>0.773260</td>\n",
       "      <td>0.730804</td>\n",
       "      <td>0.486260</td>\n",
       "      <td>-0.425539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Input 2</td>\n",
       "      <td>-0.572129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.523798</td>\n",
       "      <td>-0.542286</td>\n",
       "      <td>-0.474648</td>\n",
       "      <td>-0.662293</td>\n",
       "      <td>-0.468049</td>\n",
       "      <td>-0.488811</td>\n",
       "      <td>-0.502784</td>\n",
       "      <td>-0.469200</td>\n",
       "      <td>-0.376060</td>\n",
       "      <td>0.135722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Input 3</td>\n",
       "      <td>0.939954</td>\n",
       "      <td>-0.523798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893738</td>\n",
       "      <td>0.667783</td>\n",
       "      <td>0.823420</td>\n",
       "      <td>0.598575</td>\n",
       "      <td>0.588904</td>\n",
       "      <td>0.676809</td>\n",
       "      <td>0.639960</td>\n",
       "      <td>0.422647</td>\n",
       "      <td>-0.407844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Input 4</td>\n",
       "      <td>0.950208</td>\n",
       "      <td>-0.542286</td>\n",
       "      <td>0.893738</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817663</td>\n",
       "      <td>0.877718</td>\n",
       "      <td>0.728996</td>\n",
       "      <td>0.727916</td>\n",
       "      <td>0.826244</td>\n",
       "      <td>0.795714</td>\n",
       "      <td>0.534825</td>\n",
       "      <td>-0.367517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Input 5</td>\n",
       "      <td>0.775150</td>\n",
       "      <td>-0.474648</td>\n",
       "      <td>0.667783</td>\n",
       "      <td>0.817663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870063</td>\n",
       "      <td>0.926586</td>\n",
       "      <td>0.917741</td>\n",
       "      <td>0.977178</td>\n",
       "      <td>0.891651</td>\n",
       "      <td>0.693503</td>\n",
       "      <td>-0.346663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Input 6</td>\n",
       "      <td>0.894622</td>\n",
       "      <td>-0.662293</td>\n",
       "      <td>0.823420</td>\n",
       "      <td>0.877718</td>\n",
       "      <td>0.870063</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780521</td>\n",
       "      <td>0.775963</td>\n",
       "      <td>0.878146</td>\n",
       "      <td>0.829034</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>-0.418134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Input 7</td>\n",
       "      <td>0.700969</td>\n",
       "      <td>-0.468049</td>\n",
       "      <td>0.598575</td>\n",
       "      <td>0.728996</td>\n",
       "      <td>0.926586</td>\n",
       "      <td>0.780521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954663</td>\n",
       "      <td>0.881863</td>\n",
       "      <td>0.818400</td>\n",
       "      <td>0.524209</td>\n",
       "      <td>-0.435386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Input 8</td>\n",
       "      <td>0.687356</td>\n",
       "      <td>-0.488811</td>\n",
       "      <td>0.588904</td>\n",
       "      <td>0.727916</td>\n",
       "      <td>0.917741</td>\n",
       "      <td>0.775963</td>\n",
       "      <td>0.954663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882597</td>\n",
       "      <td>0.812763</td>\n",
       "      <td>0.538514</td>\n",
       "      <td>-0.399113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Input 9</td>\n",
       "      <td>0.773260</td>\n",
       "      <td>-0.502784</td>\n",
       "      <td>0.676809</td>\n",
       "      <td>0.826244</td>\n",
       "      <td>0.977178</td>\n",
       "      <td>0.878146</td>\n",
       "      <td>0.881863</td>\n",
       "      <td>0.882597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894913</td>\n",
       "      <td>0.754854</td>\n",
       "      <td>-0.288443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Input 10</td>\n",
       "      <td>0.730804</td>\n",
       "      <td>-0.469200</td>\n",
       "      <td>0.639960</td>\n",
       "      <td>0.795714</td>\n",
       "      <td>0.891651</td>\n",
       "      <td>0.829034</td>\n",
       "      <td>0.818400</td>\n",
       "      <td>0.812763</td>\n",
       "      <td>0.894913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695695</td>\n",
       "      <td>-0.293095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Input 11</td>\n",
       "      <td>0.486260</td>\n",
       "      <td>-0.376060</td>\n",
       "      <td>0.422647</td>\n",
       "      <td>0.534825</td>\n",
       "      <td>0.693503</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>0.524209</td>\n",
       "      <td>0.538514</td>\n",
       "      <td>0.754854</td>\n",
       "      <td>0.695695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Input 12</td>\n",
       "      <td>-0.425539</td>\n",
       "      <td>0.135722</td>\n",
       "      <td>-0.407844</td>\n",
       "      <td>-0.367517</td>\n",
       "      <td>-0.346663</td>\n",
       "      <td>-0.418134</td>\n",
       "      <td>-0.435386</td>\n",
       "      <td>-0.399113</td>\n",
       "      <td>-0.288443</td>\n",
       "      <td>-0.293095</td>\n",
       "      <td>-0.011089</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Input 1   Input 2   Input 3   Input 4   Input 5   Input 6  \\\n",
       "Input 1    1.000000 -0.572129  0.939954  0.950208  0.775150  0.894622   \n",
       "Input 2   -0.572129  1.000000 -0.523798 -0.542286 -0.474648 -0.662293   \n",
       "Input 3    0.939954 -0.523798  1.000000  0.893738  0.667783  0.823420   \n",
       "Input 4    0.950208 -0.542286  0.893738  1.000000  0.817663  0.877718   \n",
       "Input 5    0.775150 -0.474648  0.667783  0.817663  1.000000  0.870063   \n",
       "Input 6    0.894622 -0.662293  0.823420  0.877718  0.870063  1.000000   \n",
       "Input 7    0.700969 -0.468049  0.598575  0.728996  0.926586  0.780521   \n",
       "Input 8    0.687356 -0.488811  0.588904  0.727916  0.917741  0.775963   \n",
       "Input 9    0.773260 -0.502784  0.676809  0.826244  0.977178  0.878146   \n",
       "Input 10   0.730804 -0.469200  0.639960  0.795714  0.891651  0.829034   \n",
       "Input 11   0.486260 -0.376060  0.422647  0.534825  0.693503  0.689591   \n",
       "Input 12  -0.425539  0.135722 -0.407844 -0.367517 -0.346663 -0.418134   \n",
       "\n",
       "            Input 7   Input 8   Input 9  Input 10   Input 11   Input 12  \n",
       "Input 1    0.700969  0.687356  0.773260   0.730804   0.486260 -0.425539  \n",
       "Input 2   -0.468049 -0.488811 -0.502784  -0.469200  -0.376060  0.135722  \n",
       "Input 3    0.598575  0.588904  0.676809   0.639960   0.422647 -0.407844  \n",
       "Input 4    0.728996  0.727916  0.826244   0.795714   0.534825 -0.367517  \n",
       "Input 5    0.926586  0.917741  0.977178   0.891651   0.693503 -0.346663  \n",
       "Input 6    0.780521  0.775963  0.878146   0.829034   0.689591 -0.418134  \n",
       "Input 7    1.000000  0.954663  0.881863   0.818400   0.524209 -0.435386  \n",
       "Input 8    0.954663  1.000000  0.882597   0.812763   0.538514 -0.399113  \n",
       "Input 9    0.881863  0.882597  1.000000   0.894913   0.754854 -0.288443  \n",
       "Input 10   0.818400  0.812763  0.894913   1.000000   0.695695 -0.293095  \n",
       "Input 11   0.524209  0.538514  0.754854   0.695695   1.000000 -0.011089  \n",
       "Input 12  -0.435386 -0.399113 -0.288443  -0.293095  -0.011089  1.000000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input correlelations to see 2 most related features\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two features (inputs) with the highest correlation are Input 5 and Input 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style='color:green'> Data Visualization</h2>\n",
    "<h3>Bar charts using pandas dataframe (mean value of the sensors)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean values are: \n",
      "Input 1      3.689240\n",
      "Input 2      1.935515\n",
      "Input 3      5.003099\n",
      "Input 4      4.690429\n",
      "Input 5      1.010839\n",
      "Input 6      1.528013\n",
      "Input 7      0.709361\n",
      "Input 8      0.380582\n",
      "Input 9      0.907347\n",
      "Input 10     2.890093\n",
      "Input 11     1.910864\n",
      "Input 12     2.963230\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.mean().plot(kind='bar')\n",
    "#get column names\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "#exclude last column (class)\n",
    "column = columns[:len(columns)-1]\n",
    "\n",
    "#get and print the mean values for all sensors\n",
    "print('The mean values are: \\n{}'.format(df.mean()))\n",
    "\n",
    "#store mean values\n",
    "mean_values=df[:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:green'> Data Preprocessing</h2>\n",
    "<h3>Feature Matrix and Target Vector</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['class']\n",
    "X=df.loc[:, df.columns != 'class']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Converting the features dataframe to a numpy array</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.406 0.612 5.691 ... 5.083 5.503 0.754]\n",
      " [4.68  0.532 5.461 ... 5.099 5.601 0.955]\n",
      " [4.738 0.53  5.68  ... 5.127 5.535 0.728]\n",
      " ...\n",
      " [3.64  1.284 5.111 ... 1.46  1.118 4.867]\n",
      " [3.746 1.261 5.049 ... 1.482 1.128 5.627]\n",
      " [3.959 1.108 5.422 ... 1.595 1.244 5.623]]\n"
     ]
    }
   ],
   "source": [
    "X=np.array(X)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Label Encoding</h3>\n",
    "\n",
    "Transforming the categorical labels into integers using the scikit-learn label encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class labels afer encoding ['one', 'three', 'two']\n",
      "encoded values: [0 0 0 ... 2 2 2]\n",
      "encoded shape: (1463,)\n"
     ]
    }
   ],
   "source": [
    "#import label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "# encode the class labels\n",
    "y_encoded=label_encoder.fit_transform(df['class'])\n",
    "\n",
    "#print the categorical class labels we encoded (note the underscore!)\n",
    "print('class labels afer encoding', list(label_encoder.classes_))\n",
    "\n",
    "#print the encode values\n",
    "print('encoded values:',y_encoded)\n",
    "\n",
    "#print the shgape of the encoded classes\n",
    "print('encoded shape:',y_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Spliting the data into Training and Testing Sets </h2>\n",
    "\n",
    "\n",
    "<b> Using a 80% / 20% train/test split</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape of the data : (1170, 12)\n",
      "y_train Shape of the data : (1170,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train Shape of the data : {}'.format(X_train.shape))\n",
    "print('y_train Shape of the data : {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test Shape of the data : (293, 12)\n",
      "y_test Shape of the data : (293,)\n"
     ]
    }
   ],
   "source": [
    "print('X_test Shape of the data : {}'.format(X_test.shape))\n",
    "print('y_test Shape of the data : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:green'> Scale the Data</h2>\n",
    "\n",
    "\n",
    "<h3> StandardScaler from Scikit-learn to transform (scale) features </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the preceding code, I loaded the StandardScaler class from the preprocessing module and initialized a new StandardScaler object that was assigned to the variable sc.\n",
    "- Using the fit method, StandardScaler estimated the parameters μ (sample mean) and (standard deviation) for each feature dimension from the training data.\n",
    "- By calling the transform method, I then standardized the training data using those estimated parameters μ and 𝜎\n",
    "- I used the same scaling parameters to standardize the test set so that both the values in the training and test dataset are comparable to each other. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:green'> Model Building</h2>\n",
    "<h4> Here I will use three different algorithyms and compare their results </h4>\n",
    "\n",
    "1. K-Nearest Neighbor (with K=10, K=100, K=200)\n",
    "2. Logistic Regression\n",
    "3. Linear Support Vector Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:green'> Building a KNN Classification Model for K = 10, 100 and 200 </h2>\n",
    "\n",
    "<b>Next I instantiate, fit, predict and test the model's performance (accuracy) for the K-Nearest Neighbor Model in SciKit-Learn for K = 10, 100 and 200.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (using knn.score() for k = 10 is:0.986\n",
      "Model's Predictive Accuracy for k =10 is: 0.99\n",
      "Misclassified samples for k=10 are 4\n",
      "\n",
      "Test accuracy (using knn.score() for k = 100 is:0.935\n",
      "Model's Predictive Accuracy for k =100 is: 0.94\n",
      "Misclassified samples for k=100 are 19\n",
      "\n",
      "Test accuracy (using knn.score() for k = 200 is:0.826\n",
      "Model's Predictive Accuracy for k =200 is: 0.83\n",
      "Misclassified samples for k=200 are 51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "for k in [10,100,200]:\n",
    "    knn= KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    knn.fit(X_train_std,y_train)\n",
    "    y_pred=knn.predict(X_test_std)\n",
    "\n",
    "    print('Test accuracy (using knn.score() for k = {0} is:{1:0.3f}'.format(k, knn.score(X_test_std, y_test)))\n",
    "\n",
    "    print(\"Model's Predictive Accuracy for k ={0} is: {1:0.2f}\".format(k,metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    print('Misclassified samples for k={0} are {1}\\n'.format(k, (y_pred != y_test).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predicting class-membership probabilities</h3>\n",
    "\n",
    "\n",
    "\n",
    "**class membership label indices after encoding**\n",
    "\n",
    "    0 = 'one' (the Substance is Substance 1)\n",
    "    1 = 'three' (false alarm)\n",
    "    2 = 'two' (The Substance is Substance 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class membership probability is: [[0.095 0.    0.905]\n",
      " [0.73  0.    0.27 ]\n",
      " [0.63  0.37  0.   ]\n",
      " [0.955 0.    0.045]\n",
      " [0.485 0.49  0.025]\n",
      " [0.485 0.515 0.   ]\n",
      " [0.    0.11  0.89 ]\n",
      " [0.005 0.93  0.065]\n",
      " [0.485 0.395 0.12 ]\n",
      " [0.345 0.135 0.52 ]]\n"
     ]
    }
   ],
   "source": [
    "print('The predicted class membership probability is: {0}'.format(knn.predict_proba(X_test_std[:10,:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>class-membership probability</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class membership probability is: [[0.095 0.    0.905]\n",
      " [0.73  0.    0.27 ]\n",
      " [0.63  0.37  0.   ]\n",
      " [0.955 0.    0.045]\n",
      " [0.485 0.49  0.025]\n",
      " [0.485 0.515 0.   ]\n",
      " [0.    0.11  0.89 ]\n",
      " [0.005 0.93  0.065]\n",
      " [0.485 0.395 0.12 ]\n",
      " [0.345 0.135 0.52 ]\n",
      " [0.985 0.    0.015]\n",
      " [0.05  0.945 0.005]\n",
      " [0.06  0.93  0.01 ]\n",
      " [0.    0.2   0.8  ]\n",
      " [0.96  0.    0.04 ]\n",
      " [0.06  0.705 0.235]\n",
      " [0.055 0.94  0.005]\n",
      " [0.975 0.    0.025]\n",
      " [0.265 0.    0.735]\n",
      " [0.065 0.    0.935]\n",
      " [0.11  0.57  0.32 ]\n",
      " [0.385 0.    0.615]\n",
      " [0.96  0.    0.04 ]\n",
      " [0.105 0.31  0.585]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.035 0.535 0.43 ]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.06  0.66  0.28 ]\n",
      " [0.11  0.89  0.   ]\n",
      " [0.065 0.    0.935]\n",
      " [0.045 0.125 0.83 ]\n",
      " [0.13  0.035 0.835]\n",
      " [0.02  0.34  0.64 ]\n",
      " [0.055 0.    0.945]\n",
      " [0.08  0.92  0.   ]\n",
      " [0.485 0.515 0.   ]\n",
      " [0.965 0.    0.035]\n",
      " [0.96  0.    0.04 ]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.405 0.34  0.255]\n",
      " [0.49  0.51  0.   ]\n",
      " [0.035 0.93  0.035]\n",
      " [0.035 0.93  0.035]\n",
      " [0.005 0.26  0.735]\n",
      " [0.74  0.    0.26 ]\n",
      " [0.64  0.    0.36 ]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.09  0.635 0.275]\n",
      " [0.425 0.    0.575]\n",
      " [0.98  0.    0.02 ]\n",
      " [0.98  0.    0.02 ]\n",
      " [0.125 0.66  0.215]\n",
      " [0.485 0.515 0.   ]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.005 0.67  0.325]\n",
      " [0.35  0.06  0.59 ]\n",
      " [0.01  0.17  0.82 ]\n",
      " [0.115 0.    0.885]\n",
      " [0.065 0.    0.935]\n",
      " [0.965 0.    0.035]\n",
      " [0.81  0.    0.19 ]\n",
      " [0.23  0.06  0.71 ]\n",
      " [0.04  0.525 0.435]\n",
      " [0.075 0.92  0.005]\n",
      " [0.035 0.93  0.035]\n",
      " [0.395 0.12  0.485]\n",
      " [0.    0.055 0.945]\n",
      " [0.08  0.    0.92 ]\n",
      " [0.    0.11  0.89 ]\n",
      " [0.14  0.725 0.135]\n",
      " [0.    0.125 0.875]\n",
      " [0.105 0.64  0.255]\n",
      " [0.035 0.    0.965]\n",
      " [0.065 0.    0.935]\n",
      " [0.21  0.    0.79 ]\n",
      " [0.    0.105 0.895]\n",
      " [0.485 0.51  0.005]\n",
      " [0.385 0.115 0.5  ]\n",
      " [0.975 0.    0.025]\n",
      " [0.025 0.    0.975]\n",
      " [0.505 0.495 0.   ]\n",
      " [0.055 0.67  0.275]\n",
      " [0.26  0.74  0.   ]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.485 0.515 0.   ]\n",
      " [0.    0.225 0.775]\n",
      " [0.    0.09  0.91 ]\n",
      " [0.385 0.005 0.61 ]\n",
      " [0.075 0.625 0.3  ]\n",
      " [0.98  0.    0.02 ]\n",
      " [0.06  0.215 0.725]\n",
      " [0.025 0.    0.975]\n",
      " [0.94  0.    0.06 ]\n",
      " [0.085 0.    0.915]\n",
      " [0.    0.05  0.95 ]\n",
      " [0.04  0.    0.96 ]\n",
      " [0.    0.06  0.94 ]\n",
      " [0.04  0.375 0.585]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.945 0.    0.055]\n",
      " [0.485 0.505 0.01 ]\n",
      " [0.405 0.355 0.24 ]\n",
      " [0.055 0.    0.945]\n",
      " [0.39  0.025 0.585]\n",
      " [0.    0.11  0.89 ]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.03  0.92  0.05 ]\n",
      " [0.175 0.    0.825]\n",
      " [0.05  0.945 0.005]\n",
      " [0.05  0.94  0.01 ]\n",
      " [0.4   0.345 0.255]\n",
      " [0.485 0.49  0.025]\n",
      " [0.405 0.34  0.255]\n",
      " [0.155 0.    0.845]\n",
      " [0.075 0.    0.925]\n",
      " [0.06  0.    0.94 ]\n",
      " [0.11  0.89  0.   ]\n",
      " [0.385 0.    0.615]\n",
      " [0.29  0.3   0.41 ]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.08  0.665 0.255]\n",
      " [0.125 0.325 0.55 ]\n",
      " [0.1   0.73  0.17 ]\n",
      " [0.4   0.17  0.43 ]\n",
      " [0.005 0.9   0.095]]\n"
     ]
    }
   ],
   "source": [
    "print('The predicted class membership probability is: {0}'.format(knn.predict_proba(X_test_std[:125,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Class-membership probability</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class membership probability is: [[0.095 0.    0.905]\n",
      " [0.73  0.    0.27 ]\n",
      " [0.63  0.37  0.   ]\n",
      " [0.955 0.    0.045]\n",
      " [0.485 0.49  0.025]\n",
      " [0.485 0.515 0.   ]\n",
      " [0.    0.11  0.89 ]\n",
      " [0.005 0.93  0.065]\n",
      " [0.485 0.395 0.12 ]\n",
      " [0.345 0.135 0.52 ]\n",
      " [0.985 0.    0.015]\n",
      " [0.05  0.945 0.005]\n",
      " [0.06  0.93  0.01 ]\n",
      " [0.    0.2   0.8  ]\n",
      " [0.96  0.    0.04 ]\n",
      " [0.06  0.705 0.235]\n",
      " [0.055 0.94  0.005]\n",
      " [0.975 0.    0.025]\n",
      " [0.265 0.    0.735]\n",
      " [0.065 0.    0.935]\n",
      " [0.11  0.57  0.32 ]\n",
      " [0.385 0.    0.615]\n",
      " [0.96  0.    0.04 ]\n",
      " [0.105 0.31  0.585]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.035 0.535 0.43 ]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.06  0.66  0.28 ]\n",
      " [0.11  0.89  0.   ]\n",
      " [0.065 0.    0.935]\n",
      " [0.045 0.125 0.83 ]\n",
      " [0.13  0.035 0.835]\n",
      " [0.02  0.34  0.64 ]\n",
      " [0.055 0.    0.945]\n",
      " [0.08  0.92  0.   ]\n",
      " [0.485 0.515 0.   ]\n",
      " [0.965 0.    0.035]\n",
      " [0.96  0.    0.04 ]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.405 0.34  0.255]\n",
      " [0.49  0.51  0.   ]\n",
      " [0.035 0.93  0.035]\n",
      " [0.035 0.93  0.035]\n",
      " [0.005 0.26  0.735]\n",
      " [0.74  0.    0.26 ]\n",
      " [0.64  0.    0.36 ]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.09  0.635 0.275]\n",
      " [0.425 0.    0.575]\n",
      " [0.98  0.    0.02 ]\n",
      " [0.98  0.    0.02 ]\n",
      " [0.125 0.66  0.215]\n",
      " [0.485 0.515 0.   ]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.005 0.67  0.325]\n",
      " [0.35  0.06  0.59 ]\n",
      " [0.01  0.17  0.82 ]\n",
      " [0.115 0.    0.885]\n",
      " [0.065 0.    0.935]\n",
      " [0.965 0.    0.035]\n",
      " [0.81  0.    0.19 ]\n",
      " [0.23  0.06  0.71 ]\n",
      " [0.04  0.525 0.435]\n",
      " [0.075 0.92  0.005]\n",
      " [0.035 0.93  0.035]\n",
      " [0.395 0.12  0.485]\n",
      " [0.    0.055 0.945]\n",
      " [0.08  0.    0.92 ]\n",
      " [0.    0.11  0.89 ]\n",
      " [0.14  0.725 0.135]\n",
      " [0.    0.125 0.875]\n",
      " [0.105 0.64  0.255]\n",
      " [0.035 0.    0.965]\n",
      " [0.065 0.    0.935]\n",
      " [0.21  0.    0.79 ]\n",
      " [0.    0.105 0.895]\n",
      " [0.485 0.51  0.005]\n",
      " [0.385 0.115 0.5  ]\n",
      " [0.975 0.    0.025]\n",
      " [0.025 0.    0.975]\n",
      " [0.505 0.495 0.   ]\n",
      " [0.055 0.67  0.275]\n",
      " [0.26  0.74  0.   ]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.485 0.515 0.   ]\n",
      " [0.    0.225 0.775]\n",
      " [0.    0.09  0.91 ]\n",
      " [0.385 0.005 0.61 ]\n",
      " [0.075 0.625 0.3  ]\n",
      " [0.98  0.    0.02 ]\n",
      " [0.06  0.215 0.725]\n",
      " [0.025 0.    0.975]\n",
      " [0.94  0.    0.06 ]\n",
      " [0.085 0.    0.915]\n",
      " [0.    0.05  0.95 ]\n",
      " [0.04  0.    0.96 ]\n",
      " [0.    0.06  0.94 ]\n",
      " [0.04  0.375 0.585]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.945 0.    0.055]\n",
      " [0.485 0.505 0.01 ]\n",
      " [0.405 0.355 0.24 ]\n",
      " [0.055 0.    0.945]\n",
      " [0.39  0.025 0.585]\n",
      " [0.    0.11  0.89 ]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.03  0.92  0.05 ]\n",
      " [0.175 0.    0.825]\n",
      " [0.05  0.945 0.005]\n",
      " [0.05  0.94  0.01 ]\n",
      " [0.4   0.345 0.255]\n",
      " [0.485 0.49  0.025]\n",
      " [0.405 0.34  0.255]\n",
      " [0.155 0.    0.845]\n",
      " [0.075 0.    0.925]\n",
      " [0.06  0.    0.94 ]\n",
      " [0.11  0.89  0.   ]\n",
      " [0.385 0.    0.615]\n",
      " [0.29  0.3   0.41 ]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.08  0.665 0.255]\n",
      " [0.125 0.325 0.55 ]\n",
      " [0.1   0.73  0.17 ]\n",
      " [0.4   0.17  0.43 ]\n",
      " [0.005 0.9   0.095]\n",
      " [0.975 0.    0.025]\n",
      " [0.405 0.33  0.265]\n",
      " [0.04  0.955 0.005]\n",
      " [0.38  0.34  0.28 ]\n",
      " [0.4   0.    0.6  ]\n",
      " [0.29  0.    0.71 ]\n",
      " [0.375 0.01  0.615]\n",
      " [0.38  0.38  0.24 ]\n",
      " [0.57  0.43  0.   ]\n",
      " [0.94  0.    0.06 ]\n",
      " [0.04  0.575 0.385]\n",
      " [0.065 0.925 0.01 ]\n",
      " [0.08  0.    0.92 ]\n",
      " [0.03  0.46  0.51 ]\n",
      " [0.985 0.    0.015]\n",
      " [0.08  0.    0.92 ]\n",
      " [0.09  0.91  0.   ]\n",
      " [0.38  0.    0.62 ]\n",
      " [0.09  0.    0.91 ]\n",
      " [0.225 0.575 0.2  ]\n",
      " [0.005 0.915 0.08 ]\n",
      " [0.03  0.935 0.035]\n",
      " [0.205 0.    0.795]\n",
      " [0.4   0.335 0.265]\n",
      " [0.07  0.005 0.925]\n",
      " [0.07  0.    0.93 ]\n",
      " [0.    0.08  0.92 ]\n",
      " [0.095 0.    0.905]\n",
      " [0.96  0.    0.04 ]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.    0.085 0.915]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.    0.12  0.88 ]\n",
      " [0.09  0.    0.91 ]\n",
      " [0.585 0.    0.415]\n",
      " [0.965 0.    0.035]\n",
      " [0.    0.1   0.9  ]\n",
      " [0.065 0.52  0.415]\n",
      " [0.    0.145 0.855]\n",
      " [0.05  0.94  0.01 ]\n",
      " [0.815 0.    0.185]\n",
      " [0.49  0.51  0.   ]\n",
      " [0.96  0.    0.04 ]\n",
      " [0.405 0.015 0.58 ]\n",
      " [0.49  0.51  0.   ]\n",
      " [0.96  0.    0.04 ]\n",
      " [0.445 0.32  0.235]\n",
      " [0.975 0.    0.025]\n",
      " [0.05  0.94  0.01 ]\n",
      " [0.505 0.495 0.   ]\n",
      " [0.97  0.    0.03 ]\n",
      " [0.965 0.    0.035]\n",
      " [0.04  0.45  0.51 ]\n",
      " [0.965 0.    0.035]\n",
      " [0.02  0.91  0.07 ]\n",
      " [0.07  0.    0.93 ]\n",
      " [0.035 0.92  0.045]\n",
      " [0.11  0.665 0.225]\n",
      " [0.    0.645 0.355]\n",
      " [0.5   0.5   0.   ]\n",
      " [0.055 0.935 0.01 ]\n",
      " [0.125 0.875 0.   ]\n",
      " [0.22  0.56  0.22 ]\n",
      " [0.055 0.    0.945]\n",
      " [0.485 0.455 0.06 ]\n",
      " [0.34  0.025 0.635]\n",
      " [0.085 0.715 0.2  ]\n",
      " [0.96  0.    0.04 ]\n",
      " [0.93  0.    0.07 ]\n",
      " [0.25  0.72  0.03 ]\n",
      " [0.145 0.    0.855]\n",
      " [0.965 0.    0.035]\n",
      " [0.515 0.    0.485]\n",
      " [0.055 0.    0.945]\n",
      " [0.975 0.    0.025]]\n"
     ]
    }
   ],
   "source": [
    "print('The predicted class membership probability is: {0}'.format(knn.predict_proba(X_test_std[:200,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:green'> Building a Logistic Regression Classification Model  </h2>\n",
    "\n",
    "<b> Importing and Instantiating the Logistic Regression Model in SciKit-Learn</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='newton-cg',\n",
    "                       multi_class='multinomial',\n",
    "                       random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training the model by calling the model's fit function</h3>\n",
    "\n",
    "Now that the model has been instantiated (created) it still needs to be trained (fitted) to the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluate the Logistic Regression Model</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      " ['two' 'one' 'one' 'one' 'one' 'one' 'two' 'three' 'three' 'one' 'one'\n",
      " 'three' 'three' 'two' 'one' 'three' 'three' 'one' 'two' 'two' 'three'\n",
      " 'one' 'one' 'two' 'one' 'three' 'one' 'three' 'three' 'two' 'two' 'two'\n",
      " 'two' 'two' 'three' 'one' 'one' 'one' 'one' 'one' 'one' 'three' 'three'\n",
      " 'two' 'one' 'one' 'one' 'three' 'two' 'one' 'one' 'three' 'one' 'one'\n",
      " 'three' 'one' 'two' 'two' 'two' 'one' 'one' 'one' 'three' 'three' 'three'\n",
      " 'one' 'two' 'two' 'two' 'three' 'two' 'three' 'two' 'two' 'two' 'two'\n",
      " 'one' 'one' 'one' 'two' 'one' 'three' 'three' 'one' 'one' 'two' 'two'\n",
      " 'one' 'three' 'one' 'two' 'two' 'one' 'two' 'two' 'two' 'two' 'three'\n",
      " 'one' 'one' 'one' 'one' 'two' 'one' 'two' 'one' 'three' 'two' 'three'\n",
      " 'three' 'one' 'one' 'one' 'two' 'two' 'two' 'three' 'one' 'one' 'one'\n",
      " 'three' 'one' 'three' 'one' 'three' 'one' 'one' 'three' 'one' 'two' 'two'\n",
      " 'one' 'one' 'one' 'one' 'three' 'three' 'two' 'three' 'one' 'two' 'three'\n",
      " 'one' 'two' 'three' 'three' 'three' 'two' 'one' 'two' 'two' 'two' 'two'\n",
      " 'one' 'one' 'two' 'one' 'two' 'two' 'one' 'one' 'two' 'three' 'two'\n",
      " 'three' 'one' 'one' 'one' 'one' 'one' 'one' 'one' 'one' 'three' 'one'\n",
      " 'one' 'one' 'three' 'one' 'three' 'two' 'three' 'three' 'three' 'one'\n",
      " 'three' 'three' 'three' 'two' 'one' 'one' 'three' 'one' 'one' 'three'\n",
      " 'two' 'one' 'two' 'two' 'one' 'two' 'one' 'three' 'two' 'two' 'two' 'one'\n",
      " 'one' 'two' 'three' 'three' 'two' 'two' 'two' 'one' 'three' 'two' 'two'\n",
      " 'one' 'three' 'one' 'two' 'one' 'one' 'three' 'one' 'one' 'three' 'one'\n",
      " 'one' 'one' 'three' 'three' 'three' 'two' 'three' 'three' 'one' 'two'\n",
      " 'one' 'one' 'one' 'two' 'two' 'two' 'three' 'one' 'one' 'two' 'three'\n",
      " 'one' 'two' 'one' 'two' 'one' 'three' 'three' 'one' 'one' 'two' 'one'\n",
      " 'one' 'three' 'one' 'three' 'one' 'three' 'one' 'two' 'one' 'one' 'two'\n",
      " 'one' 'two' 'one' 'one' 'three' 'one' 'two' 'one' 'two' 'two' 'one' 'one'\n",
      " 'one' 'three' 'one' 'two' 'two' 'two' 'three' 'one' 'one']\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test_std)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluate the Logistic Regression Model's Performance</h3>\n",
    "\n",
    "\n",
    "Using SciKit Learn's built-in scoring method to evaluate the model's performance accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 97.61%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest set accuracy: {0:0.2f}%'.format(100*lr.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predicting class-membership probabilities using the Logistic Regression Model</h3>\n",
    "\n",
    "<h3>Class-membership probability</h3>\n",
    "\n",
    "\n",
    "Predicting the class membership probability by using the row with **index=10** from the X_test_std data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted probability for belonging to the classes[class 0 = one, class 1 = false alarm, class 2 = two] are [[1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.027 0.013 0.96 ]\n",
      " [1.    0.    0.   ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [0.015 0.    0.985]\n",
      " [0.001 0.    0.999]\n",
      " [0.003 0.981 0.016]\n",
      " [0.872 0.007 0.121]\n",
      " [0.768 0.    0.232]\n",
      " [0.126 0.108 0.766]\n",
      " [0.992 0.    0.008]\n",
      " [0.004 0.993 0.003]\n",
      " [0.999 0.    0.001]\n",
      " [0.004 0.958 0.038]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.001 0.    0.999]\n",
      " [0.116 0.017 0.868]\n",
      " [0.076 0.021 0.903]\n",
      " [0.094 0.37  0.536]\n",
      " [0.001 0.    0.999]\n",
      " [0.    1.    0.   ]\n",
      " [0.939 0.06  0.001]\n",
      " [1.    0.    0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [1.    0.    0.   ]\n",
      " [0.938 0.032 0.03 ]\n",
      " [0.999 0.001 0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.019 0.167 0.814]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.991 0.    0.009]\n",
      " [1.    0.    0.   ]\n",
      " [0.001 0.993 0.007]\n",
      " [0.293 0.    0.707]\n",
      " [0.996 0.    0.004]\n",
      " [0.993 0.    0.007]\n",
      " [0.004 0.996 0.   ]\n",
      " [0.964 0.036 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.011 0.971 0.018]\n",
      " [0.954 0.004 0.043]\n",
      " [0.088 0.055 0.857]\n",
      " [0.001 0.    0.999]\n",
      " [0.002 0.    0.998]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.995 0.    0.005]\n",
      " [0.879 0.003 0.118]\n",
      " [0.023 0.956 0.021]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.987 0.013 0.001]\n",
      " [0.001 0.    0.999]\n",
      " [0.001 0.    0.999]\n",
      " [0.002 0.001 0.997]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.009 0.011 0.98 ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.003 0.    0.997]\n",
      " [0.002 0.    0.998]\n",
      " [0.366 0.005 0.629]\n",
      " [0.001 0.002 0.997]\n",
      " [0.928 0.071 0.001]\n",
      " [0.993 0.006 0.001]\n",
      " [1.    0.    0.   ]\n",
      " [0.001 0.    0.999]\n",
      " [0.982 0.018 0.   ]\n",
      " [0.003 0.997 0.   ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.996 0.    0.004]\n",
      " [0.999 0.001 0.001]\n",
      " [0.001 0.001 0.998]\n",
      " [0.004 0.011 0.986]\n",
      " [0.996 0.002 0.002]\n",
      " [0.003 0.996 0.   ]\n",
      " [0.996 0.    0.004]\n",
      " [0.009 0.001 0.991]\n",
      " [0.001 0.    0.999]\n",
      " [0.849 0.    0.151]\n",
      " [0.006 0.    0.994]\n",
      " [0.002 0.002 0.996]\n",
      " [0.    0.    1.   ]\n",
      " [0.001 0.003 0.997]\n",
      " [0.007 0.808 0.186]\n",
      " [1.    0.    0.   ]\n",
      " [0.929 0.    0.071]\n",
      " [0.967 0.032 0.001]\n",
      " [0.866 0.074 0.06 ]\n",
      " [0.001 0.    0.999]\n",
      " [0.98  0.    0.02 ]\n",
      " [0.008 0.019 0.973]\n",
      " [0.929 0.    0.071]\n",
      " [0.002 0.997 0.   ]\n",
      " [0.001 0.    0.999]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.632 0.167 0.201]\n",
      " [0.915 0.08  0.005]\n",
      " [0.804 0.096 0.101]\n",
      " [0.031 0.    0.969]\n",
      " [0.005 0.    0.995]\n",
      " [0.003 0.    0.997]\n",
      " [0.003 0.997 0.   ]\n",
      " [0.947 0.016 0.037]\n",
      " [0.698 0.007 0.295]\n",
      " [0.869 0.    0.131]\n",
      " [0.    1.    0.   ]\n",
      " [0.508 0.094 0.399]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.999 0.001 0.   ]\n",
      " [0.001 0.998 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.793 0.042 0.165]\n",
      " [0.    1.    0.   ]\n",
      " [0.994 0.006 0.   ]\n",
      " [0.043 0.    0.957]\n",
      " [0.243 0.    0.757]\n",
      " [0.901 0.003 0.096]\n",
      " [0.621 0.238 0.141]\n",
      " [0.996 0.004 0.   ]\n",
      " [0.994 0.    0.006]\n",
      " [0.007 0.992 0.001]\n",
      " [0.    1.    0.   ]\n",
      " [0.002 0.    0.998]\n",
      " [0.003 0.914 0.083]\n",
      " [0.999 0.    0.001]\n",
      " [0.002 0.    0.998]\n",
      " [0.    1.    0.   ]\n",
      " [0.701 0.014 0.285]\n",
      " [0.002 0.    0.998]\n",
      " [0.023 0.976 0.001]\n",
      " [0.001 0.998 0.001]\n",
      " [0.    1.    0.   ]\n",
      " [0.006 0.    0.994]\n",
      " [0.688 0.057 0.255]\n",
      " [0.002 0.    0.998]\n",
      " [0.001 0.    0.999]\n",
      " [0.002 0.001 0.997]\n",
      " [0.003 0.    0.997]\n",
      " [0.999 0.    0.001]\n",
      " [1.    0.    0.   ]\n",
      " [0.002 0.002 0.996]\n",
      " [1.    0.    0.   ]\n",
      " [0.008 0.019 0.973]\n",
      " [0.003 0.    0.997]\n",
      " [0.649 0.    0.351]\n",
      " [0.881 0.    0.119]\n",
      " [0.003 0.009 0.988]\n",
      " [0.01  0.988 0.003]\n",
      " [0.004 0.002 0.994]\n",
      " [0.    1.    0.   ]\n",
      " [0.948 0.    0.052]\n",
      " [0.998 0.001 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.977 0.014 0.009]\n",
      " [0.999 0.    0.001]\n",
      " [0.787 0.    0.213]\n",
      " [0.916 0.011 0.073]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.981 0.019 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.994 0.    0.006]\n",
      " [0.06  0.856 0.084]\n",
      " [0.994 0.    0.006]\n",
      " [0.001 0.998 0.001]\n",
      " [0.    0.    1.   ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.003 0.997 0.   ]\n",
      " [0.001 0.976 0.023]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.011 0.988 0.001]\n",
      " [0.001 0.    0.999]\n",
      " [0.873 0.125 0.002]\n",
      " [0.892 0.001 0.108]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [0.933 0.    0.067]\n",
      " [0.    1.    0.   ]\n",
      " [0.011 0.    0.989]\n",
      " [0.998 0.    0.002]\n",
      " [0.257 0.    0.743]\n",
      " [0.001 0.    0.999]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.003 0.    0.997]\n",
      " [0.986 0.    0.013]\n",
      " [0.022 0.978 0.   ]\n",
      " [0.003 0.001 0.996]\n",
      " [0.001 0.004 0.995]\n",
      " [0.002 0.002 0.996]\n",
      " [0.996 0.004 0.   ]\n",
      " [0.895 0.102 0.003]\n",
      " [0.02  0.116 0.864]\n",
      " [0.002 0.998 0.   ]\n",
      " [0.104 0.895 0.001]\n",
      " [0.213 0.    0.787]\n",
      " [0.001 0.002 0.997]\n",
      " [0.013 0.028 0.959]\n",
      " [0.999 0.    0.001]\n",
      " [0.    1.    0.   ]\n",
      " [0.    0.011 0.989]\n",
      " [0.071 0.018 0.911]\n",
      " [0.923 0.075 0.001]\n",
      " [0.093 0.907 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.024 0.    0.976]\n",
      " [1.    0.    0.   ]\n",
      " [0.925 0.    0.075]\n",
      " [0.    1.    0.   ]\n",
      " [0.817 0.023 0.16 ]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.886 0.001 0.113]\n",
      " [0.998 0.002 0.   ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.354 0.    0.646]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.933 0.    0.067]\n",
      " [0.405 0.    0.595]\n",
      " [0.995 0.    0.005]\n",
      " [0.999 0.    0.001]\n",
      " [0.812 0.004 0.184]\n",
      " [0.001 0.003 0.996]\n",
      " [0.127 0.    0.873]\n",
      " [0.033 0.008 0.958]\n",
      " [0.003 0.997 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.794 0.001 0.205]\n",
      " [0.001 0.    0.999]\n",
      " [0.002 0.997 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.079 0.    0.921]\n",
      " [0.886 0.113 0.001]\n",
      " [0.001 0.001 0.998]\n",
      " [0.971 0.029 0.001]\n",
      " [0.001 0.955 0.044]\n",
      " [0.002 0.998 0.   ]\n",
      " [0.937 0.001 0.062]\n",
      " [1.    0.    0.   ]\n",
      " [0.011 0.    0.989]\n",
      " [0.998 0.    0.002]\n",
      " [0.771 0.008 0.221]\n",
      " [0.    1.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.019 0.981 0.   ]\n",
      " [0.987 0.    0.013]\n",
      " [0.    1.    0.   ]\n",
      " [0.998 0.001 0.   ]\n",
      " [0.003 0.008 0.988]\n",
      " [0.999 0.    0.001]\n",
      " [0.984 0.014 0.003]\n",
      " [0.058 0.    0.942]\n",
      " [0.981 0.019 0.   ]\n",
      " [0.032 0.207 0.761]\n",
      " [0.996 0.    0.004]\n",
      " [0.995 0.003 0.002]\n",
      " [0.    1.    0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [0.001 0.    0.999]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.    0.    1.   ]\n",
      " [0.362 0.009 0.629]\n",
      " [0.999 0.001 0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [0.999 0.    0.001]\n",
      " [0.043 0.923 0.034]\n",
      " [0.998 0.002 0.   ]\n",
      " [0.001 0.    0.999]\n",
      " [0.004 0.002 0.994]\n",
      " [0.    0.003 0.997]\n",
      " [0.    1.    0.   ]\n",
      " [0.984 0.    0.016]\n",
      " [1.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('The predicted probability for belonging to the classes[class 0 = one, class 1 = false alarm, class 2 = two] are {0}'.format(lr.predict_proba(X_test_std[10:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Class-membership probability</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted probability for belonging to the classes[class 0 = one, class 1 = false alarm, class 2 = two] are [[0.001 0.    0.999]\n",
      " [0.973 0.    0.027]\n",
      " [0.999 0.    0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [0.898 0.1   0.002]\n",
      " [0.998 0.001 0.001]\n",
      " [0.073 0.005 0.921]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.109 0.89  0.001]\n",
      " [0.947 0.003 0.049]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.027 0.013 0.96 ]\n",
      " [1.    0.    0.   ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [0.015 0.    0.985]\n",
      " [0.001 0.    0.999]\n",
      " [0.003 0.981 0.016]\n",
      " [0.872 0.007 0.121]\n",
      " [0.768 0.    0.232]\n",
      " [0.126 0.108 0.766]\n",
      " [0.992 0.    0.008]\n",
      " [0.004 0.993 0.003]\n",
      " [0.999 0.    0.001]\n",
      " [0.004 0.958 0.038]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.001 0.    0.999]\n",
      " [0.116 0.017 0.868]\n",
      " [0.076 0.021 0.903]\n",
      " [0.094 0.37  0.536]\n",
      " [0.001 0.    0.999]\n",
      " [0.    1.    0.   ]\n",
      " [0.939 0.06  0.001]\n",
      " [1.    0.    0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [1.    0.    0.   ]\n",
      " [0.938 0.032 0.03 ]\n",
      " [0.999 0.001 0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.019 0.167 0.814]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.991 0.    0.009]\n",
      " [1.    0.    0.   ]\n",
      " [0.001 0.993 0.007]\n",
      " [0.293 0.    0.707]\n",
      " [0.996 0.    0.004]\n",
      " [0.993 0.    0.007]\n",
      " [0.004 0.996 0.   ]\n",
      " [0.964 0.036 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.011 0.971 0.018]\n",
      " [0.954 0.004 0.043]\n",
      " [0.088 0.055 0.857]\n",
      " [0.001 0.    0.999]\n",
      " [0.002 0.    0.998]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.995 0.    0.005]\n",
      " [0.879 0.003 0.118]\n",
      " [0.023 0.956 0.021]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.987 0.013 0.001]\n",
      " [0.001 0.    0.999]\n",
      " [0.001 0.    0.999]\n",
      " [0.002 0.001 0.997]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.009 0.011 0.98 ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.003 0.    0.997]\n",
      " [0.002 0.    0.998]\n",
      " [0.366 0.005 0.629]\n",
      " [0.001 0.002 0.997]\n",
      " [0.928 0.071 0.001]\n",
      " [0.993 0.006 0.001]\n",
      " [1.    0.    0.   ]\n",
      " [0.001 0.    0.999]\n",
      " [0.982 0.018 0.   ]\n",
      " [0.003 0.997 0.   ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.996 0.    0.004]\n",
      " [0.999 0.001 0.001]\n",
      " [0.001 0.001 0.998]\n",
      " [0.004 0.011 0.986]\n",
      " [0.996 0.002 0.002]\n",
      " [0.003 0.996 0.   ]\n",
      " [0.996 0.    0.004]\n",
      " [0.009 0.001 0.991]\n",
      " [0.001 0.    0.999]\n",
      " [0.849 0.    0.151]\n",
      " [0.006 0.    0.994]\n",
      " [0.002 0.002 0.996]\n",
      " [0.    0.    1.   ]\n",
      " [0.001 0.003 0.997]\n",
      " [0.007 0.808 0.186]\n",
      " [1.    0.    0.   ]\n",
      " [0.929 0.    0.071]\n",
      " [0.967 0.032 0.001]\n",
      " [0.866 0.074 0.06 ]\n",
      " [0.001 0.    0.999]\n",
      " [0.98  0.    0.02 ]\n",
      " [0.008 0.019 0.973]\n",
      " [0.929 0.    0.071]\n",
      " [0.002 0.997 0.   ]\n",
      " [0.001 0.    0.999]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.632 0.167 0.201]\n",
      " [0.915 0.08  0.005]\n",
      " [0.804 0.096 0.101]\n",
      " [0.031 0.    0.969]\n",
      " [0.005 0.    0.995]\n",
      " [0.003 0.    0.997]\n",
      " [0.003 0.997 0.   ]\n",
      " [0.947 0.016 0.037]\n",
      " [0.698 0.007 0.295]\n",
      " [0.869 0.    0.131]]\n"
     ]
    }
   ],
   "source": [
    "print('The predicted probability for belonging to the classes[class 0 = one, class 1 = false alarm, class 2 = two] are {0}'.format(lr.predict_proba(X_test_std[:120])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Class-membership probability</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted probability for belonging to the classes[class 0 = one, class 1 = false alarm, class 2 = two] are [[0.001 0.    0.999]\n",
      " [0.973 0.    0.027]\n",
      " [0.999 0.    0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [0.898 0.1   0.002]\n",
      " [0.998 0.001 0.001]\n",
      " [0.073 0.005 0.921]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.109 0.89  0.001]\n",
      " [0.947 0.003 0.049]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.027 0.013 0.96 ]\n",
      " [1.    0.    0.   ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [0.015 0.    0.985]\n",
      " [0.001 0.    0.999]\n",
      " [0.003 0.981 0.016]\n",
      " [0.872 0.007 0.121]\n",
      " [0.768 0.    0.232]\n",
      " [0.126 0.108 0.766]\n",
      " [0.992 0.    0.008]\n",
      " [0.004 0.993 0.003]\n",
      " [0.999 0.    0.001]\n",
      " [0.004 0.958 0.038]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.001 0.    0.999]\n",
      " [0.116 0.017 0.868]\n",
      " [0.076 0.021 0.903]\n",
      " [0.094 0.37  0.536]\n",
      " [0.001 0.    0.999]\n",
      " [0.    1.    0.   ]\n",
      " [0.939 0.06  0.001]\n",
      " [1.    0.    0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [1.    0.    0.   ]\n",
      " [0.938 0.032 0.03 ]\n",
      " [0.999 0.001 0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.019 0.167 0.814]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.991 0.    0.009]\n",
      " [1.    0.    0.   ]\n",
      " [0.001 0.993 0.007]\n",
      " [0.293 0.    0.707]\n",
      " [0.996 0.    0.004]\n",
      " [0.993 0.    0.007]\n",
      " [0.004 0.996 0.   ]\n",
      " [0.964 0.036 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.011 0.971 0.018]\n",
      " [0.954 0.004 0.043]\n",
      " [0.088 0.055 0.857]\n",
      " [0.001 0.    0.999]\n",
      " [0.002 0.    0.998]\n",
      " [0.99  0.    0.01 ]\n",
      " [0.995 0.    0.005]\n",
      " [0.879 0.003 0.118]\n",
      " [0.023 0.956 0.021]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.987 0.013 0.001]\n",
      " [0.001 0.    0.999]\n",
      " [0.001 0.    0.999]\n",
      " [0.002 0.001 0.997]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.009 0.011 0.98 ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.003 0.    0.997]\n",
      " [0.002 0.    0.998]\n",
      " [0.366 0.005 0.629]\n",
      " [0.001 0.002 0.997]\n",
      " [0.928 0.071 0.001]\n",
      " [0.993 0.006 0.001]\n",
      " [1.    0.    0.   ]\n",
      " [0.001 0.    0.999]\n",
      " [0.982 0.018 0.   ]\n",
      " [0.003 0.997 0.   ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.996 0.    0.004]\n",
      " [0.999 0.001 0.001]\n",
      " [0.001 0.001 0.998]\n",
      " [0.004 0.011 0.986]\n",
      " [0.996 0.002 0.002]\n",
      " [0.003 0.996 0.   ]\n",
      " [0.996 0.    0.004]\n",
      " [0.009 0.001 0.991]\n",
      " [0.001 0.    0.999]\n",
      " [0.849 0.    0.151]\n",
      " [0.006 0.    0.994]\n",
      " [0.002 0.002 0.996]\n",
      " [0.    0.    1.   ]\n",
      " [0.001 0.003 0.997]\n",
      " [0.007 0.808 0.186]\n",
      " [1.    0.    0.   ]\n",
      " [0.929 0.    0.071]\n",
      " [0.967 0.032 0.001]\n",
      " [0.866 0.074 0.06 ]\n",
      " [0.001 0.    0.999]\n",
      " [0.98  0.    0.02 ]\n",
      " [0.008 0.019 0.973]\n",
      " [0.929 0.    0.071]\n",
      " [0.002 0.997 0.   ]\n",
      " [0.001 0.    0.999]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.632 0.167 0.201]\n",
      " [0.915 0.08  0.005]\n",
      " [0.804 0.096 0.101]\n",
      " [0.031 0.    0.969]\n",
      " [0.005 0.    0.995]\n",
      " [0.003 0.    0.997]\n",
      " [0.003 0.997 0.   ]\n",
      " [0.947 0.016 0.037]\n",
      " [0.698 0.007 0.295]\n",
      " [0.869 0.    0.131]\n",
      " [0.    1.    0.   ]\n",
      " [0.508 0.094 0.399]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.999 0.001 0.   ]\n",
      " [0.001 0.998 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.793 0.042 0.165]\n",
      " [0.    1.    0.   ]\n",
      " [0.994 0.006 0.   ]\n",
      " [0.043 0.    0.957]\n",
      " [0.243 0.    0.757]\n",
      " [0.901 0.003 0.096]\n",
      " [0.621 0.238 0.141]\n",
      " [0.996 0.004 0.   ]\n",
      " [0.994 0.    0.006]\n",
      " [0.007 0.992 0.001]\n",
      " [0.    1.    0.   ]\n",
      " [0.002 0.    0.998]\n",
      " [0.003 0.914 0.083]\n",
      " [0.999 0.    0.001]\n",
      " [0.002 0.    0.998]\n",
      " [0.    1.    0.   ]\n",
      " [0.701 0.014 0.285]\n",
      " [0.002 0.    0.998]\n",
      " [0.023 0.976 0.001]\n",
      " [0.001 0.998 0.001]\n",
      " [0.    1.    0.   ]\n",
      " [0.006 0.    0.994]\n",
      " [0.688 0.057 0.255]\n",
      " [0.002 0.    0.998]\n",
      " [0.001 0.    0.999]\n",
      " [0.002 0.001 0.997]\n",
      " [0.003 0.    0.997]\n",
      " [0.999 0.    0.001]\n",
      " [1.    0.    0.   ]\n",
      " [0.002 0.002 0.996]\n",
      " [1.    0.    0.   ]\n",
      " [0.008 0.019 0.973]\n",
      " [0.003 0.    0.997]\n",
      " [0.649 0.    0.351]\n",
      " [0.881 0.    0.119]\n",
      " [0.003 0.009 0.988]\n",
      " [0.01  0.988 0.003]\n",
      " [0.004 0.002 0.994]\n",
      " [0.    1.    0.   ]\n",
      " [0.948 0.    0.052]\n",
      " [0.998 0.001 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.977 0.014 0.009]\n",
      " [0.999 0.    0.001]\n",
      " [0.787 0.    0.213]\n",
      " [0.916 0.011 0.073]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.981 0.019 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.994 0.    0.006]\n",
      " [0.06  0.856 0.084]\n",
      " [0.994 0.    0.006]\n",
      " [0.001 0.998 0.001]\n",
      " [0.    0.    1.   ]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.003 0.997 0.   ]\n",
      " [0.001 0.976 0.023]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.011 0.988 0.001]\n",
      " [0.001 0.    0.999]\n",
      " [0.873 0.125 0.002]\n",
      " [0.892 0.001 0.108]\n",
      " [0.001 0.999 0.   ]\n",
      " [0.999 0.    0.001]\n",
      " [0.933 0.    0.067]\n",
      " [0.    1.    0.   ]\n",
      " [0.011 0.    0.989]\n",
      " [0.998 0.    0.002]\n",
      " [0.257 0.    0.743]\n",
      " [0.001 0.    0.999]\n",
      " [0.99  0.    0.01 ]]\n"
     ]
    }
   ],
   "source": [
    "print('The predicted probability for belonging to the classes[class 0 = one, class 1 = false alarm, class 2 = two] are {0}'.format(lr.predict_proba(X_test_std[:200])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:green'> Building Linear Support Vector Classifier Model</h2>\n",
    "<h3>Scikit-learn Linear Support Vector Classifier </h3>\n",
    "Importing and instantiating the Linear Support Vector Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "lsv = svm.SVC(probability=True, kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training the model by calling the model's fit function</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsv.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating the Linear Support Vector Classifier Model</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      " ['two' 'one' 'one' 'one' 'one' 'one' 'two' 'three' 'three' 'one' 'one'\n",
      " 'three' 'three' 'two' 'one' 'three' 'three' 'one' 'two' 'two' 'three'\n",
      " 'one' 'one' 'two' 'one' 'three' 'one' 'three' 'three' 'two' 'two' 'two'\n",
      " 'three' 'two' 'three' 'one' 'one' 'one' 'one' 'one' 'one' 'three' 'three'\n",
      " 'two' 'one' 'one' 'one' 'three' 'two' 'one' 'one' 'three' 'one' 'one'\n",
      " 'three' 'one' 'two' 'two' 'two' 'one' 'one' 'one' 'three' 'three' 'three'\n",
      " 'one' 'two' 'two' 'two' 'three' 'two' 'three' 'two' 'two' 'two' 'two'\n",
      " 'one' 'one' 'one' 'two' 'one' 'three' 'three' 'one' 'one' 'two' 'two'\n",
      " 'one' 'three' 'one' 'two' 'two' 'one' 'two' 'two' 'two' 'two' 'three'\n",
      " 'one' 'one' 'one' 'one' 'two' 'one' 'two' 'one' 'three' 'two' 'three'\n",
      " 'three' 'one' 'one' 'one' 'two' 'two' 'two' 'three' 'one' 'one' 'one'\n",
      " 'three' 'one' 'three' 'one' 'three' 'one' 'one' 'three' 'one' 'two' 'two'\n",
      " 'one' 'one' 'one' 'one' 'three' 'three' 'two' 'three' 'one' 'two' 'three'\n",
      " 'one' 'two' 'three' 'three' 'three' 'two' 'one' 'two' 'two' 'two' 'two'\n",
      " 'one' 'one' 'two' 'one' 'two' 'two' 'one' 'one' 'two' 'three' 'two'\n",
      " 'three' 'one' 'one' 'one' 'one' 'one' 'one' 'one' 'one' 'three' 'one'\n",
      " 'one' 'one' 'three' 'one' 'three' 'two' 'three' 'three' 'three' 'one'\n",
      " 'three' 'three' 'three' 'two' 'one' 'one' 'three' 'one' 'one' 'three'\n",
      " 'two' 'one' 'two' 'two' 'one' 'two' 'one' 'three' 'two' 'two' 'two' 'one'\n",
      " 'one' 'two' 'three' 'three' 'two' 'two' 'two' 'one' 'three' 'two' 'two'\n",
      " 'one' 'three' 'one' 'two' 'one' 'one' 'three' 'one' 'one' 'three' 'one'\n",
      " 'one' 'one' 'three' 'three' 'three' 'two' 'three' 'three' 'one' 'two'\n",
      " 'one' 'one' 'one' 'two' 'two' 'two' 'three' 'one' 'one' 'two' 'three'\n",
      " 'one' 'two' 'one' 'two' 'one' 'three' 'three' 'one' 'one' 'two' 'one'\n",
      " 'one' 'three' 'one' 'three' 'one' 'three' 'one' 'two' 'one' 'one' 'two'\n",
      " 'one' 'two' 'one' 'one' 'three' 'one' 'two' 'one' 'two' 'two' 'one' 'one'\n",
      " 'one' 'three' 'one' 'two' 'two' 'two' 'three' 'one' 'one']\n",
      "\n",
      "Test set accuracy: 97.95%\n"
     ]
    }
   ],
   "source": [
    "y_pred = lsv.predict(X_test_std)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))\n",
    "print('\\nTest set accuracy: {0:0.2f}%'.format(100*lsv.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating the Linear Support Vector Model's Performance</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's performance accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's performance accuracy: {0:0.3f}\".format(lsv.score(X_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using the Predict Method of the Linear Support Vector Model </h3>\n",
    "\n",
    "\n",
    "Using SciKit Learn's built-in predict method to test the model's predictive performance for the first row of data in X_test_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.977, 0.   , 0.023],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.852, 0.121, 0.027],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.043, 0.013, 0.944],\n",
       "       [0.   , 0.999, 0.001],\n",
       "       [0.092, 0.907, 0.001],\n",
       "       [0.926, 0.008, 0.066],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 0.999, 0.001],\n",
       "       [0.018, 0.019, 0.963],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.009, 0.   , 0.991],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.995, 0.005],\n",
       "       [0.87 , 0.002, 0.128],\n",
       "       [0.788, 0.   , 0.212],\n",
       "       [0.118, 0.369, 0.514],\n",
       "       [0.991, 0.   , 0.009],\n",
       "       [0.   , 0.998, 0.002],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.001, 0.986, 0.013],\n",
       "       [0.   , 0.998, 0.002],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.052, 0.02 , 0.928],\n",
       "       [0.064, 0.037, 0.899],\n",
       "       [0.051, 0.659, 0.29 ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.965, 0.029, 0.007],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.978, 0.012, 0.011],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.999, 0.001],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.006, 0.092, 0.903],\n",
       "       [0.994, 0.   , 0.006],\n",
       "       [0.994, 0.   , 0.006],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.998, 0.002],\n",
       "       [0.258, 0.001, 0.741],\n",
       "       [0.996, 0.   , 0.004],\n",
       "       [0.992, 0.   , 0.008],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.004, 0.977, 0.019],\n",
       "       [0.931, 0.01 , 0.059],\n",
       "       [0.039, 0.017, 0.944],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.992, 0.   , 0.008],\n",
       "       [0.997, 0.   , 0.003],\n",
       "       [0.873, 0.   , 0.127],\n",
       "       [0.008, 0.989, 0.003],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 0.999, 0.001],\n",
       "       [0.965, 0.035, 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.001, 0.004, 0.995],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.002, 0.004, 0.994],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.002, 0.   , 0.998],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.369, 0.016, 0.615],\n",
       "       [0.   , 0.008, 0.991],\n",
       "       [0.961, 0.031, 0.007],\n",
       "       [0.994, 0.006, 0.001],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.002, 0.998, 0.   ],\n",
       "       [0.996, 0.   , 0.004],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.   , 0.003, 0.997],\n",
       "       [0.001, 0.005, 0.994],\n",
       "       [0.995, 0.003, 0.002],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.997, 0.   , 0.003],\n",
       "       [0.007, 0.003, 0.99 ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.834, 0.   , 0.166],\n",
       "       [0.003, 0.   , 0.997],\n",
       "       [0.001, 0.004, 0.996],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.002, 0.998],\n",
       "       [0.002, 0.864, 0.134],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.93 , 0.   , 0.07 ],\n",
       "       [0.976, 0.02 , 0.003],\n",
       "       [0.956, 0.024, 0.02 ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.985, 0.001, 0.013],\n",
       "       [0.002, 0.005, 0.993],\n",
       "       [0.924, 0.   , 0.076],\n",
       "       [0.   , 0.997, 0.003],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.815, 0.112, 0.072],\n",
       "       [0.942, 0.046, 0.013],\n",
       "       [0.904, 0.059, 0.037],\n",
       "       [0.022, 0.   , 0.978],\n",
       "       [0.003, 0.   , 0.997],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.998, 0.002],\n",
       "       [0.965, 0.008, 0.027],\n",
       "       [0.772, 0.032, 0.196],\n",
       "       [0.86 , 0.   , 0.14 ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.374, 0.2  , 0.425],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.998, 0.002, 0.   ],\n",
       "       [0.   , 0.998, 0.002],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.914, 0.032, 0.054],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.992, 0.008, 0.   ],\n",
       "       [0.028, 0.   , 0.972],\n",
       "       [0.23 , 0.001, 0.769],\n",
       "       [0.866, 0.002, 0.133],\n",
       "       [0.81 , 0.136, 0.053],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.995, 0.   , 0.005],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.001, 0.973, 0.026],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.691, 0.005, 0.304],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.028, 0.971, 0.   ],\n",
       "       [0.   , 0.998, 0.002],\n",
       "       [0.   , 0.999, 0.001],\n",
       "       [0.003, 0.   , 0.997],\n",
       "       [0.833, 0.065, 0.102],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.001, 0.003, 0.996],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.003, 0.009, 0.988],\n",
       "       [0.002, 0.   , 0.998],\n",
       "       [0.66 , 0.   , 0.339],\n",
       "       [0.86 , 0.   , 0.14 ],\n",
       "       [0.001, 0.009, 0.99 ],\n",
       "       [0.   , 0.998, 0.002],\n",
       "       [0.002, 0.002, 0.996],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.955, 0.001, 0.044],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.976, 0.015, 0.009],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.779, 0.   , 0.221],\n",
       "       [0.966, 0.009, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.994, 0.   , 0.006],\n",
       "       [0.021, 0.867, 0.112],\n",
       "       [0.993, 0.   , 0.007],\n",
       "       [0.   , 0.997, 0.003],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.999, 0.001],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 0.988, 0.012],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.008, 0.992, 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.805, 0.159, 0.036],\n",
       "       [0.853, 0.001, 0.145],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.922, 0.   , 0.078],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.006, 0.   , 0.994],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.252, 0.001, 0.747],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.986, 0.   , 0.014],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.989, 0.   , 0.011],\n",
       "       [0.011, 0.989, 0.   ],\n",
       "       [0.001, 0.001, 0.998],\n",
       "       [0.   , 0.002, 0.998],\n",
       "       [0.001, 0.004, 0.996],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.875, 0.099, 0.026],\n",
       "       [0.007, 0.033, 0.96 ],\n",
       "       [0.006, 0.994, 0.   ],\n",
       "       [0.071, 0.911, 0.017],\n",
       "       [0.143, 0.   , 0.857],\n",
       "       [0.   , 0.003, 0.997],\n",
       "       [0.004, 0.006, 0.99 ],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 0.012, 0.988],\n",
       "       [0.028, 0.015, 0.957],\n",
       "       [0.917, 0.069, 0.014],\n",
       "       [0.117, 0.866, 0.017],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.016, 0.   , 0.984],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.93 , 0.   , 0.07 ],\n",
       "       [0.   , 0.999, 0.001],\n",
       "       [0.866, 0.025, 0.108],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.999, 0.001],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.817, 0.002, 0.18 ],\n",
       "       [0.996, 0.004, 0.   ],\n",
       "       [0.003, 0.997, 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 0.999, 0.001],\n",
       "       [0.315, 0.   , 0.685],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.907, 0.002, 0.092],\n",
       "       [0.332, 0.   , 0.668],\n",
       "       [0.997, 0.   , 0.003],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.725, 0.007, 0.269],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.098, 0.   , 0.902],\n",
       "       [0.012, 0.007, 0.982],\n",
       "       [0.01 , 0.99 , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.712, 0.003, 0.285],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.998, 0.002],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.059, 0.   , 0.94 ],\n",
       "       [0.887, 0.092, 0.021],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.976, 0.02 , 0.004],\n",
       "       [0.   , 0.989, 0.011],\n",
       "       [0.   , 0.998, 0.002],\n",
       "       [0.914, 0.   , 0.085],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.004, 0.   , 0.996],\n",
       "       [0.998, 0.   , 0.002],\n",
       "       [0.672, 0.003, 0.324],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.02 , 0.98 , 0.   ],\n",
       "       [0.978, 0.001, 0.021],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.998, 0.001, 0.   ],\n",
       "       [0.001, 0.004, 0.995],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.991, 0.007, 0.003],\n",
       "       [0.044, 0.   , 0.956],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.013, 0.049, 0.938],\n",
       "       [0.997, 0.   , 0.003],\n",
       "       [0.997, 0.   , 0.002],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.998, 0.   , 0.002],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.988, 0.   , 0.012],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.389, 0.008, 0.603],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.999, 0.   , 0.001],\n",
       "       [0.017, 0.976, 0.007],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.002, 0.001, 0.997],\n",
       "       [0.   , 0.005, 0.994],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.984, 0.   , 0.016],\n",
       "       [1.   , 0.   , 0.   ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsv.predict_proba(X_test_std[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Printing the number of misclassifications using numpy </h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples = 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of misclassified samples = {0}\\n'.format((y_pred != y_test).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='color:green'>Confusion Matrix</h2>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[128   0   3]\n",
      " [  0  76   1]\n",
      " [  2   0  83]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classification Correctness</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of correct classifications for substance two is 83 according to the third row and column of the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classification report for Linear Support Vector Model</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         one       0.98      0.98      0.98       131\n",
      "         two       1.00      0.99      0.99        77\n",
      "       three       0.95      0.98      0.97        85\n",
      "\n",
      "    accuracy                           0.98       293\n",
      "   macro avg       0.98      0.98      0.98       293\n",
      "weighted avg       0.98      0.98      0.98       293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = ['one','two', 'three']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the classification report f1-score substance 1 was correctly predicted 79% of the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style='color:purple'>Comparative Summary of Models Performance</h3>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classification Model\n",
    "\n",
    "My KKN  model had an accuracy of 98.6%. This model was the most accuracte when k = 10. \n",
    "\n",
    "####  Logistic Regression Model\n",
    "\n",
    "The Logistic Regression model's accuracy was 97.61%. This model performed the worst on this dataset. \n",
    "\n",
    "#### Linear Support Vector Classification Model\n",
    "\n",
    "The Linear Support Vector model's accuracy was 98.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this project I created three different machine learning algs; K-Nearest neighbor, logistic regression, and linear support vector classifier models. While these models are what we gain statistical insights from, there are various processes that need to be performed on the data before building the models. After importing the data and printing a descriptive statistical summary we cleaned the data using pandas and numpy to change all the -9999 values to nan values. Next I we moved on to data preprocessing where we performed label encoding and trained the dataset. I followed this up by scaling the data to standardize the training data and test set. This standardization makes the values in the training and test dataset comparable moving forward. \n",
    "My first model used the k-nearest neighbor algorithm to determine the class memberships.  Through this method, the object is assigned to the class most common amongst its closest “k” neighbors, and in this case I used 10,100, and 200.   The accuracies were greater the lower our value of k became.  Having high k values defeats the purpose of KNN depending upon the dataset size because eventually a closest neighbor will not share features which are valuable in the classification process.  The KNN model provided the greatest degree of accuracy when K=10 with test accuracy of 98.6%.  \n",
    "The second model was logistic regression which predicts the probability of a classification as a function on the features. After training this model using the fit function, I am able to begin evaluation by using the test set to create and display the model’s class prediction vector. With the logistic regression model I was also able to determine the model’s performance by calculating the test set accuracy and predicting class-membership probabilities at specified indices. \n",
    "The third model built was the Linear Support Vector Classifier using SciKit-Learn. Like the previous models I train and fit the data before making the model’s predictions and determining performance accuracy and number of misclassification samples. Although you are able to perform many of the same steps with these different models the internal processes are different. For example, Logistic regression uses the entire dataset to perform its functions while the LSVC model only considers the points near the support vectors.   \n",
    "While the KNN model when K = 10 happened to be the most accurate on this dataset it may not be the most reliable because the accuracy significantly dropped when you change the K value. If I was able to be working on a dataset with linear solutions then the Logistic Regression model would be the ideal model to use out of the three built. However, the Logistic Regression model cannot support non-linear solutions like the KNN and LSVC model can. After building the models I computed the confusion matrix and classification report in order to perform the comparative analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Quantitave Values have changed since clearing Kernal and running several times***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
